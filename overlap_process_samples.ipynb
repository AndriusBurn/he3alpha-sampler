{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful imports\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "import sys; sys.path.append('./')\n",
    "import models\n",
    "from data_loader import DataLoader\n",
    "import emcee, corner\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "import numpy.linalg as lin\n",
    "import seaborn as sns\n",
    "import numpy.typing as npt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 3\n",
    "\n",
    "# File name to process\n",
    "directory = './11_15_2023/run{}/'.format(number)\n",
    "file_name = directory + 'samples_{}.h5'.format(number, number)\n",
    "save_name = directory + 'samples{}.npy'.format(number, number)\n",
    "n_burn = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the samples\n",
    "reader = emcee.backends.HDFBackend(file_name)\n",
    "samples_not_flat = reader.get_chain()\n",
    "samples_flat = reader.get_chain(flat = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(0.676, 2.624, 'som')\n",
    "data = loader.get_data()\n",
    "norm_group = loader.get_normalization_grouping()\n",
    "gauss_prior_f = loader.get_normalization_prior_info()\n",
    "\n",
    "labels = ['A0', 'r0', 'C1+^2', 'P1+', 'C1-^2', 'P1-']\n",
    "# Add normalization labels\n",
    "for i in range(0, int(np.max(norm_group) + 1)):\n",
    "    labels.append('f_{}'.format(i))\n",
    "\n",
    "def generate_trace_plot(samples_not_flat):\n",
    "    # Generate the trace plot given a set of samples\n",
    "    fig, axes = plt.subplots(samples_not_flat.shape[2], figsize = (20, 40))\n",
    "    for i in range(0, samples_not_flat.shape[2]):\n",
    "        ax = axes[i]\n",
    "        for j in range(0, samples_not_flat.shape[1]):\n",
    "            ax.plot(samples_not_flat[:, :, i][:, j])\n",
    "            ax.set_ylabel(labels[i])\n",
    "    axes[-1].set_xlabel('Step Number')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 bad walkers at indices:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Look at the variances within each chain to determine if the walker is moving enough or if it is stuck.\n",
    "within_chain_means = np.mean(samples_not_flat[n_burn:, :, :], axis = 0)\n",
    "\n",
    "# Create an empty array of the within chain variances\n",
    "within_chain_var = np.empty(within_chain_means.shape)\n",
    "\n",
    "# Run a for loop across all walkers to compute the within chain variance\n",
    "for i in range(0, within_chain_means.shape[0]):\n",
    "    within_chain_var[i, :] = np.sum(np.square(within_chain_means[i, :] - samples_not_flat[n_burn:, i, :]), axis = 0) / (samples_not_flat.shape[0] // 2)\n",
    "\n",
    "# Get the typical within chain variance W for each parameter\n",
    "W = np.median(within_chain_var, axis = 0)\n",
    "\n",
    "\n",
    "# Now we need to loop over each chain for each parameter to see how it compares to the typical variance\n",
    "bad_indices = []\n",
    "ratios = np.empty(within_chain_means.shape)\n",
    "# Loop over each parameter\n",
    "for i in range(0, within_chain_means.shape[1]):\n",
    "    # Loop over the walkers\n",
    "    for j in range(0, within_chain_means.shape[0]):\n",
    "        ratio = np.sum(within_chain_var[j, i] / W[i]) / within_chain_means.shape[1]\n",
    "        ratios[j, i] = ratio\n",
    "\n",
    "# Sum along each parameter, this value should be very close to 1.0. Select out the bad indices\n",
    "total_normalized_ratios = np.sum(ratios, axis = 1)\n",
    "bad_indices = np.where(total_normalized_ratios <= 0.9)[0]\n",
    "print('Found {} bad walkers at indices:'.format(bad_indices.shape[0]))\n",
    "print(bad_indices)\n",
    "\n",
    "if bad_indices.shape[0] != 0:\n",
    "    # Remove the bad walkers\n",
    "    samples_not_flat = np.delete(samples_not_flat, bad_indices, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_trace_plot(samples_not_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocorrelation time: 612\n"
     ]
    }
   ],
   "source": [
    "# Thin according to the burn-in time\n",
    "thinned_samples_not_flat = samples_not_flat[n_burn:, :, :]\n",
    "\n",
    "# Compute the autocorrelation times for each parameter\n",
    "ac_s = reader.get_autocorr_time(discard = n_burn, tol = 0)\n",
    "ac = int(np.max(ac_s))\n",
    "\n",
    "print('Autocorrelation time: {}'.format(ac))\n",
    "\n",
    "# Thin according to the autocorrelation time\n",
    "thinned_samples_not_flat = thinned_samples_not_flat[::ac, :, :]\n",
    "\n",
    "# Flatten the samples and log-prob\n",
    "len0, len1, len2 = thinned_samples_not_flat.shape\n",
    "samples = np.reshape(thinned_samples_not_flat, (len0 * len1, len2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_trace_plot(thinned_samples_not_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(save_name, thinned_samples_not_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def get_ac(single_chain: npt.ArrayLike, tau_max: int = None) -> int:\n",
    "# #     N = single_chain.shape[0]\n",
    "# #     if tau_max is None:\n",
    "# #         tau_max = N // 10\n",
    "\n",
    "# def ac_function1(single_chain: npt.ArrayLike, tau: int) -> float:\n",
    "#     mean = np.mean(single_chain)\n",
    "#     N = single_chain.shape[0]\n",
    "#     c = 0\n",
    "#     for n in range(0, int(N - tau)):\n",
    "#         c += (single_chain[n] - mean) * (single_chain[n + tau] - mean)\n",
    "#     c *= 1 / (N - tau)\n",
    "#     return c\n",
    "\n",
    "# def ac_function2(single_chain: npt.ArrayLike, tau: int, norm: bool = True) -> float:\n",
    "#     mean = np.mean(single_chain)\n",
    "#     N = single_chain.shape[0]\n",
    "#     c = np.sum((single_chain[:int(N - tau)] - mean) * (single_chain[tau:] - mean)) / (N - tau)\n",
    "#     if norm:\n",
    "#         c /= np.sum(np.square(single_chain[:] - mean)) / N\n",
    "#     return c\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ac_function2(samples_not_flat[50000:, 0, 0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain_number = 0\n",
    "# param_number = 3\n",
    "\n",
    "# taus = np.arange(0, samples_not_flat.shape[0]//100)\n",
    "# acs = [ac_function2(samples_not_flat[50000:, chain_number, param_number], tau) for tau in taus]\n",
    "# plt.plot(taus, acs)\n",
    "# plt.plot(int(ac_s[param_number]), acs[int(ac_s[param_number])], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ac_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_number = 3\n",
    "# all_acs = []\n",
    "# for chain_number in range(0, samples_not_flat.shape[1]):\n",
    "#     taus = np.arange(0, samples_not_flat.shape[0]//100)\n",
    "#     acs = [ac_function2(samples_not_flat[50000:, chain_number, param_number], tau) for tau in taus]\n",
    "#     all_acs.append(acs)\n",
    "#     plt.plot(taus, acs, alpha = 0.2)\n",
    "# plt.plot(int(ac_s[param_number]), acs[int(ac_s[param_number])], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, 26):\n",
    "#     plt.plot(taus, all_acs[i], alpha = 0.2)\n",
    "#     plt.plot(int(ac_s[param_number]), all_acs[i][int(ac_s[param_number])], 'o', alpha = 0.3)\n",
    "# # plt.plot(taus, np.median(all_acs, axis = 0), 'k')\n",
    "# plt.plot(taus, np.mean(all_acs, axis = 0), 'k')\n",
    "# plt.yscale('log')\n",
    "# plt.xlim(0, 700)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_average = []\n",
    "# for i in range(0, 26):\n",
    "#     real_tau = []\n",
    "#     for M in range(0, samples_not_flat.shape[0]//100):\n",
    "#         real_tau.append(1 + 2 * np.sum(all_acs[i][:M]))\n",
    "#     real_tau = np.array(real_tau)\n",
    "#     # to_average.append(real_tau[1912])\n",
    "#     to_average.append(real_tau[2400])\n",
    "#     mod = 5 * real_tau\n",
    "#     plt.plot(range(0, samples_not_flat.shape[0]//100), mod, alpha = 0.2)\n",
    "# plt.plot(np.linspace(0, 2500, 10), np.linspace(0, 2500, 10))\n",
    "# lim = (1000, 3000)\n",
    "# # plt.xlim(lim)\n",
    "# # plt.ylim(lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(to_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*- coding: utf-8 -*-\n",
    "# def next_pow_two(n):\n",
    "#     \"\"\"Returns the next power of two greater than or equal to `n`\"\"\"\n",
    "#     i = 1\n",
    "#     while i < n:\n",
    "#         i = i << 1\n",
    "#     return i\n",
    "\n",
    "\n",
    "# def function_1d(x):\n",
    "#     \"\"\"Estimate the normalized autocorrelation function of a 1-D series\n",
    "\n",
    "#     Args:\n",
    "#         x: The series as a 1-D numpy array.\n",
    "\n",
    "#     Returns:\n",
    "#         array: The autocorrelation function of the time series.\n",
    "\n",
    "#     \"\"\"\n",
    "#     x = np.atleast_1d(x)\n",
    "#     if len(x.shape) != 1:\n",
    "#         raise ValueError(\"invalid dimensions for 1D autocorrelation function\")\n",
    "#     n = next_pow_two(len(x))\n",
    "\n",
    "#     # Compute the FFT and then (from that) the auto-correlation function\n",
    "#     f = np.fft.fft(x - np.mean(x), n=2 * n)\n",
    "#     acf = np.fft.ifft(f * np.conjugate(f))[: len(x)].real\n",
    "#     acf /= acf[0]\n",
    "#     return acf\n",
    "\n",
    "\n",
    "# def auto_window(taus, c):\n",
    "#     m = np.arange(len(taus)) < c * taus\n",
    "#     if np.any(m):\n",
    "#         return np.argmin(m)\n",
    "#     return len(taus) - 1\n",
    "\n",
    "\n",
    "# def integrated_time(x, c=5, tol=50, quiet=False):\n",
    "#     \"\"\"Estimate the integrated autocorrelation time of a time series.\n",
    "\n",
    "#     This estimate uses the iterative procedure described on page 16 of\n",
    "#     `Sokal's notes <https://www.semanticscholar.org/paper/Monte-Carlo-Methods-in-Statistical-Mechanics%3A-and-Sokal/0bfe9e3db30605fe2d4d26e1a288a5e2997e7225>`_ to\n",
    "#     determine a reasonable window size.\n",
    "\n",
    "#     Args:\n",
    "#         x: The time series. If multidimensional, set the time axis using the\n",
    "#             ``axis`` keyword argument and the function will be computed for\n",
    "#             every other axis.\n",
    "#         c (Optional[float]): The step size for the window search. (default:\n",
    "#             ``5``)\n",
    "#         tol (Optional[float]): The minimum number of autocorrelation times\n",
    "#             needed to trust the estimate. (default: ``50``)\n",
    "#         quiet (Optional[bool]): This argument controls the behavior when the\n",
    "#             chain is too short. If ``True``, give a warning instead of raising\n",
    "#             an :class:`AutocorrError`. (default: ``False``)\n",
    "\n",
    "#     Returns:\n",
    "#         float or array: An estimate of the integrated autocorrelation time of\n",
    "#             the time series ``x`` computed along the axis ``axis``.\n",
    "\n",
    "#     Raises\n",
    "#         AutocorrError: If the autocorrelation time can't be reliably estimated\n",
    "#             from the chain and ``quiet`` is ``False``. This normally means\n",
    "#             that the chain is too short.\n",
    "\n",
    "#     \"\"\"\n",
    "#     x = np.atleast_1d(x)\n",
    "#     if len(x.shape) == 1:\n",
    "#         x = x[:, np.newaxis, np.newaxis]\n",
    "#     if len(x.shape) == 2:\n",
    "#         x = x[:, :, np.newaxis]\n",
    "#     if len(x.shape) != 3:\n",
    "#         raise ValueError(\"invalid dimensions\")\n",
    "\n",
    "#     n_t, n_w, n_d = x.shape\n",
    "#     tau_est = np.empty(n_d)\n",
    "#     windows = np.empty(n_d, dtype=int)\n",
    "\n",
    "#     # Loop over parameters\n",
    "#     for d in range(n_d):\n",
    "#         f = np.zeros(n_t)\n",
    "#         for k in range(n_w):\n",
    "#             f += function_1d(x[:, k, d])\n",
    "#         f /= n_w\n",
    "#         taus = 2.0 * np.cumsum(f) - 1.0\n",
    "#         windows[d] = auto_window(taus, c)\n",
    "#         tau_est[d] = taus[windows[d]]\n",
    "\n",
    "#     # Check convergence\n",
    "#     flag = tol * tau_est > n_t\n",
    "\n",
    "#     # Warn or raise in the case of non-convergence\n",
    "#     if np.any(flag):\n",
    "#         msg = (\n",
    "#             \"The chain is shorter than {0} times the integrated \"\n",
    "#             \"autocorrelation time for {1} parameter(s). Use this estimate \"\n",
    "#             \"with caution and run a longer chain!\\n\"\n",
    "#         ).format(tol, np.sum(flag))\n",
    "#         msg += \"N/{0} = {1:.0f};\\ntau: {2}\".format(tol, n_t / tol, tau_est)\n",
    "#         if not quiet:\n",
    "#             raise AutocorrError(tau_est, msg)\n",
    "#         # logger.warning(msg)\n",
    "\n",
    "#     return tau_est\n",
    "\n",
    "\n",
    "# class AutocorrError(Exception):\n",
    "#     \"\"\"Raised if the chain is too short to estimate an autocorrelation time.\n",
    "\n",
    "#     The current estimate of the autocorrelation time can be accessed via the\n",
    "#     ``tau`` attribute of this exception.\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, tau, *args, **kwargs):\n",
    "#         self.tau = tau\n",
    "#         super(AutocorrError, self).__init__(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([244.42673762, 247.63713189, 256.89043183, 612.30530613,\n",
       "       268.16978394, 572.70715811, 248.68199135, 257.91391625,\n",
       "       273.2214456 , 270.1105413 , 282.42493015, 288.01376923,\n",
       "       287.27666027])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# integrated_time(samples_not_flat[n_burn:, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([244.42673762, 247.63713189, 256.89043183, 612.30530613,\n",
       "       268.16978394, 572.70715811, 248.68199135, 257.91391625,\n",
       "       273.2214456 , 270.1105413 , 282.42493015, 288.01376923,\n",
       "       287.27666027])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ac_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
